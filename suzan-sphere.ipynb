{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for Victor.\n",
    "\n",
    "Example 1 is for an arbitrary MT at teleseicmic distance (60 degrees?).\n",
    "Source depth is 15 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We search for focal mechanisms by uniformly sampling points on a unit sphere. These points are the ends of T and P axes that define a focal mechanism. \n",
    "\n",
    "Only a half sphere is computed; the other half will be similar/same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng(999)  # fixed seed for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional \n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be replaced by Caio's Ray Tracer\n",
    "\n",
    "from obspy.taup.tau_model import TauModel\n",
    "from obspy.taup.taup_create import build_taup_model\n",
    "from obspy.taup import TauPyModel, plot_travel_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be replaced by Caio's Ray Tracer\n",
    "\n",
    "ak135 = TauPyModel(model='ak135')\n",
    "model = ak135\n",
    "model_name = 'ak135'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdepth = 15   # km   - assumed quake depth  (a parameter that affects \n",
    "# take-off angles, given a distance between quake and station)\n",
    "\n",
    "b3_over_a3 = (3.4600/5.8000)**3    # ideally this S- over P-velocity \n",
    "# ratio cubed should be read directly from the velocity model that \n",
    "# is being used. My hope is Caio can provide this functionality. \n",
    "# The P and S velocities for this ratio are the velocities at the depth of the quake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [-1,1]          # for plotting \"spherical\" vector space\n",
    "dd = np.radians(5)     # sampling step size, e.g. 2 or 5 degrees, for (grid) search\n",
    "# use 5 degs for visualization, and 2 or fewer degs for searching.\n",
    "n = round(16/(dd*dd))   # approximate points on sphere\n",
    "n2 = round(n/2)         # points on half-sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What M(oment) T(ensor) to use for our fake observation \n",
    "# Global CMT convention: M_rr, M_thetatheta, M_phiphi, M_rtheta, M_rphi, M_thetaphi\n",
    "mt = [2.48,0.1,-2.58,2.59,2.02,-1.12]  # arbitrary\n",
    "\n",
    "# Definitely add code here that can visualize the beach ball corresponding to this MT\n",
    "\n",
    "# Note to Victor: the sum of the first 3 elements (trace) is zero for a double-couple mechanism.\n",
    "# do not use a MT for which you have not visualized the corresponding beach ball. \n",
    "\n",
    "# simpler examples:\n",
    "# mt = [0,0,0,0,0,1]  # strike-slip fault\n",
    "# mt = [1,-1,0,0,0,0]  # thrust fault\n",
    "# mt = [-1,1,0,0,0,0]  # normal fault\n",
    "\n",
    "\n",
    "# call code here from Marsquake code (on Omkar's github) to convert this MT \n",
    "# to corresponding parameters (for later reference), including\n",
    "# 1. the strike, dip, rake of both planes (the fault plane and the auxiliary plane)\n",
    "# 2. the azimuth and dip of each of the three axes: T, P, and N\n",
    "# 3. trace of MT, CLVD* of MT, and M_0 (total moment) \n",
    "# * CLVD = Compensated linear vector dipole, ergo: a non-double couple part of the MT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake an observation\n",
    "\n",
    "# Use the marsquake code to calculate vector A (with P, SV and SH wave amplitudes),\n",
    "# given the MT defined above, a quake depth, and\n",
    "# a distance to the observing station, which should be translated to the \n",
    "# two take-off angles for P and S waves via a ray tracing package like \n",
    "# ObsPy's TauP or Caio's Ray Tracer.\n",
    "# Multiply with a random number (to simulate not knowing absolute amplitudes\n",
    "# and call this vector Ao (\"observed\")\n",
    "\n",
    "\n",
    "Ao[0] = Ao[0]*b3_over_a3    # take into account the effect of seismic \n",
    "# velocities at the quake's depth\n",
    "so = np.array([0.5,1.5,2.0])  # sigma -- same units (and scale) as Ao! \n",
    "# (simulated observational errors)\n",
    "\n",
    "\n",
    "Aolength = np.linalg.norm(Ao)\n",
    "Ao1 = Ao/Aolength   # Ao1 = Aoh (h for hat): unit vector\n",
    "so1 = so/Aolength   # scale uncertainties the same as the main vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "# Define error ellipsoid for later plotting\n",
    "\n",
    "# Set of all spherical angles:\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "# Cartesian coordinates that correspond to the spherical angles:\n",
    "# (this is the equation of an ellipsoid):\n",
    "xe = Ao[0] + so[0] * np.outer(np.cos(u), np.sin(v))\n",
    "ye = Ao[1] + so[1] * np.outer(np.sin(u), np.sin(v))\n",
    "ze = Ao[2] + so[2] * np.outer(np.ones_like(u), np.cos(v))\n",
    "\n",
    "xe1 = Ao1[0] + so1[0] * np.outer(np.cos(u), np.sin(v))\n",
    "ye1 = Ao1[1] + so1[1] * np.outer(np.sin(u), np.sin(v))\n",
    "ze1 = Ao1[2] + so1[2] * np.outer(np.ones_like(u), np.cos(v))\n",
    "\n",
    "xsax = Ao1[0] + apprxso1 * np.outer(np.cos(u), np.sin(v))\n",
    "ysax = Ao1[1] + apprxso1 * np.outer(np.sin(u), np.sin(v))\n",
    "zsax = Ao1[2] + apprxso1 * np.outer(np.ones_like(u), np.cos(v))\n",
    "\n",
    "# plot in 3D with f=plt.figure(); a=f.add_subplot(projection='3d'); a.plot_surface(xe,ye,ze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to get take-off angles from a quake depth and \n",
    "# distance from quake to to station, using ObsPy's TauP\n",
    "\n",
    "arrivals = model.get_travel_times(source_depth_in_km=hdepth,\n",
    "                         distance_in_degree=epdist, phase_list=['P', 'S'])\n",
    "print(arrivals,'\\n')\n",
    "\n",
    "print(\"a.name, a.distance, a.time, a.ray_param, a.takeoff_angle, a.incident_angle\")\n",
    "for a in arrivals:\n",
    "    print(a.name, a.distance, a.time, a.ray_param, a.takeoff_angle, a.incident_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that there is only one arrival or choose which of multiple arrivals:\n",
    "\n",
    "Parr = arrivals[0]\n",
    "Sarr = arrivals[1]\n",
    "\n",
    "takeoff_angles = [Parr.takeoff_angle, Sarr.takeoff_angle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old approximated error sphere radius \n",
    "# (from Sita and Van der Lee (2022) - factor 1/3 disappeared from paper)\n",
    "# so1 is uncertainty scaled by the length of Ao\n",
    "e_old = np.linalg.norm(so1)/np.sqrt(3)  \n",
    "epsilon_old = np.arctan2(np.asarray(e_old),np.linalg.norm(Ao1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now search through focal mechanisms by systematically rotating T and P axes:\n",
    "\n",
    "angles = np.arange(0,np.pi,dd)  # search angles range from 0 to 180 degrees.\n",
    "\n",
    "discarded = []\n",
    "secondbest = []\n",
    "accepted = []\n",
    "old_accepted = []\n",
    "\n",
    "T0 = np.array([-1,0,0])  # \"southpole\"\n",
    "Ts = [T0]\n",
    "sphcs = [np.array([0,0])]\n",
    "for a in angles[1:]:    # a is \"take-off angle\" of T axis\n",
    "                        #(measured w.r.t. downpointing vertical) (\"latitude\")\n",
    "    ddo = dd/np.sin(a)  # need fewer sampling points on small-circle when close to the poles\n",
    "    angleso = np.arange(0,np.pi,ddo)\n",
    "    for o in angleso:   # o is azimuth of T axis (\"longitude\")\n",
    "        T = np.array([-np.cos(a), -np.sin(a)*np.cos(o), np.sin(a)*np.sin(o)])\n",
    "        Ts.append(T)\n",
    "        sphcs.append(np.degrees(np.array([o,a])))\n",
    "\n",
    "for T in Ts:\n",
    "    P0 = mtf.perp(T)   # rotate T over 90 degrees to find one P axis\n",
    "    Ps = [P0]\n",
    "    for op in angles[1:]:   # find all P axes\n",
    "        # rotate P0 over angle op around axis T - Rodrigues' rotation formula\n",
    "        # not sure what direction this rotation is in, but it shouldn't matter\n",
    "        P = P0*np.cos(op) + (np.cross(T,P0))*np.sin(op) + T*(np.dot(T,P0))*(1-np.cos(op))\n",
    "        Ps.append(P)\n",
    "    \n",
    "    # here begins the real search work:    \n",
    "    for P in Ps:\n",
    "        # vectors representing T and P axes (in r-theta-phi coordinates)\n",
    "        # reminder (for seismologists): r (up), theta (south), and phi (east)  i.e. Z (up) S, E system\n",
    "        fault1r, fault2r = ... # get strike dip rake for two fault planes from a given T and P axis (use marquake code?)\n",
    "        fault1 = [np.degrees(z) for z in fault1r] # if necessary\n",
    "        fault2 = [np.degrees(z) for z in fault2r] # if necessary\n",
    "        \n",
    "        As = ...  # predicted AP,ASV,ASH for this T,P combo (use marsquake code)\n",
    "        As[0] *= b3_over_a3  # divide by a**3 and scale with b**3  \n",
    "        As1 = As/np.linalg.norm(As)\n",
    "\n",
    "        cosos = np.dot(Ao1,As1)\n",
    "        os_angle = np.arccos(cosos)     # objective function we search for minima                     \n",
    "        \n",
    "   \n",
    "        if cosos < 1.:     # avoid cosos = 1 (perfect fit)          \n",
    "            # estimate error from ellipsoid around observed amplitudes (Ao)\n",
    "            v = As1 - cosos*Ao1 # this vector is the component of As that is _|_ to Ao\n",
    "            vlength = np.linalg.norm(v)\n",
    "            vell = v/so1        # estimate ellipsoid half width // to v\n",
    "            velllen = np.linalg.norm(vell)\n",
    "            # distance to ellipsoid surface along the line in the direction of v:\n",
    "            e = vlength/velllen  # sigma along vector v\n",
    "            epsilon = np.arctan(e) # tolerance\n",
    "            # really arctan(e/||Aohat||) but the denominator = 1\n",
    "            # This is an approximation of Victor's method, and better than what was\n",
    "            # crudely assumed in Sita and Van der Lee (2022)\n",
    "            \n",
    "            if os_angle < epsilon:\n",
    "                accepted.append([T,P,fault1,fault2,As,As1,\n",
    "                        np.degrees(os_angle),np.degrees(epsilon),os_angle/epsilon])\n",
    "            elif os_angle < 2*epsilon:\n",
    "                secondbest.append([T,P,fault1,fault2,As,As1,\n",
    "                        np.degrees(os_angle),np.degrees(epsilon),os_angle/epsilon])\n",
    "            else:\n",
    "                discarded.append([T,P,fault1,fault2,As,As1,\n",
    "                        np.degrees(os_angle),np.degrees(epsilon),os_angle/epsilon])\n",
    "            if os_angle < epsilon_old:  # old error sphere from paper\n",
    "                old_accepted.append([T,P,fault1,fault2,As,As1,\n",
    "                        np.degrees(os_angle),np.degrees(epsilon),os_angle/epsilon])\n",
    "        else:   # perfect alignment\n",
    "            accepted.append([T,P,fault1,fault2,As,As1,\n",
    "                        np.degrees(os_angle),np.degrees(epsilon),os_angle/epsilon])\n",
    "            old_accepted.append([T,P,fault1,fault2,As,As1,\n",
    "                        np.degrees(os_angle),np.degrees(epsilon),os_angle/epsilon])\n",
    "            print('One predicted A was perfectly aligned with the observed A')\n",
    "\n",
    "\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell cycles through a \"grid\" of T,P axes combos systematically, in a way that approximates uniform coverage of a (half) sphere. The cell below provides the axes themselves, in a way that is comparable to the method in the following cell, which does it randomly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corresponding version of the systematic approach:systematic \"grid\" of axes,\n",
    "# uniformly piercing a (half) sphere\n",
    "\n",
    "# generic range for covering a half sphere\n",
    "# 0 to one step before 180 degrees - \n",
    "angles = np.arange(0,np.pi,dd) \n",
    "\n",
    "vector0 = np.array([0,0,1])  \n",
    "vectors = [vector0]\n",
    "sphcs = [np.array([0,0])] \n",
    "for a in angles[1:]:    # a is co-latitude\n",
    "    ddo = dd/np.sin(a)\n",
    "    angleso = np.arange(0,np.pi,ddo)\n",
    "    for o in angleso:   # o is longitude \n",
    "        vector = max(space)*np.array([np.sin(a)*np.sin(o), np.sin(a)*np.cos(o), -np.cos(a)])\n",
    "        vectors.append(vector)\n",
    "        sphcs.append(np.degrees(np.array([o,a])))\n",
    "\n",
    "nv = len(vectors) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection\n",
    "\n",
    "randors = []\n",
    "rphcs = []\n",
    "rnos = rng.uniform(0,1,[n2,2])  # get random values btw 0 & 1, to be converted to co-latitude and longitude \n",
    "for r in rnos:\n",
    "    a = np.arccos(1-2*r[0])     # co-latitude\n",
    "    # r[0] values (theta) represent CDF* of sin(co-lat), the PDF; \n",
    "    # then write co-lat = f(y), where f is the inverse of the CDF.\n",
    "    # * CDF = Cumulative probability Density Function\n",
    "    o = r[1]*np.pi              # longitude\n",
    "    vector = max(space)*np.array([np.sin(a)*np.sin(o), np.sin(a)*np.cos(o), -np.cos(a)])\n",
    "    randors.append(vector)\n",
    "    rphcs.append(np.degrees(np.array([o,a])))\n",
    "\n",
    "nr = len(randors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and plot these sets of vectors (representing one side of axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(accepted))\n",
    "print(len(secondbest))\n",
    "print(len(discarded))\n",
    "print(len(old_accepted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0,180,2)\n",
    "plt.hist([a[6] for a in discarded], bins=bins, label='discarded',alpha=0.5)\n",
    "plt.hist([a[6] for a in old_accepted], bins=bins, label='old accepted',alpha=0.5)\n",
    "plt.hist([a[7] for a in accepted], bins=bins, label='tolerance',alpha=0.5)\n",
    "plt.hist([a[6] for a in accepted], bins=bins, label='accepted',alpha=0.8)\n",
    "plt.xlabel('angles')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed from here with beach ball visualizations, characterization, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
